{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size,\n",
    "        # stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total += len(data)\n",
    "        progress = math.ceil(batch_idx / len(train_loader) * 50)\n",
    "        print(\"\\rTrain epoch %d: %d/%d, [%-51s] %d%%\" %\n",
    "              (epoch, total, len(train_loader.dataset),\n",
    "               '-' * progress + '>', progress * 2), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest: average loss: {:.4f}, accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    epochs = 2\n",
    "    batch_size = 64\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data/MNIST', train=True, download=False,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data/MNIST', train=False, download=False, \n",
    "                       transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.1307,), (0.3081,))\n",
    "                        ])),\n",
    "        batch_size=1000, shuffle=True)\n",
    "\n",
    "    model = Net().to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.025, momentum=0.9)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "\n",
    "#     torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 1: 60000/60000, [-------------------------------------------------->] 100%\n",
      "Test: average loss: 0.0595, accuracy: 9804/10000 (98%)\n",
      "Train epoch 2: 60000/60000, [-------------------------------------------------->] 100%\n",
      "Test: average loss: 0.0519, accuracy: 9827/10000 (98%)\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "batch_size = 64\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data/MNIST', train=True, download=False,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_loader:\n",
    "    a = i\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = a[0][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img.reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 26, 26]             320\n",
      "            Conv2d-2           [-1, 64, 24, 24]          18,496\n",
      "         Dropout2d-3           [-1, 64, 12, 12]               0\n",
      "            Linear-4                  [-1, 128]       1,179,776\n",
      "         Dropout2d-5                  [-1, 128]               0\n",
      "            Linear-6                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.52\n",
      "Params size (MB): 4.58\n",
      "Estimated Total Size (MB): 5.10\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchsummary as summary\n",
    "net = Net()\n",
    "summary.summary(net.to('cuda'), (1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
