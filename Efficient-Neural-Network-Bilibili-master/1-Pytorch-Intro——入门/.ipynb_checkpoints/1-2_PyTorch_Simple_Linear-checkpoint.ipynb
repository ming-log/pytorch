{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Pytorch\n",
    "\n",
    "PyTorch是一个动态的建图的工具。不像Tensorflow那样，先建图，然后通过feed和run重复执行建好的图。相对来说，PyTorch具有更好的灵活性。\n",
    "\n",
    "\n",
    "### 如何保存参数\n",
    "\n",
    "pytorch中最重要的data type。\n",
    "\n",
    "**Tensor**： 就像ndarray一样,一维Tensor叫Vector，二维Tensor叫Matrix，三维及以上称为Tensor(张量)\n",
    "\n",
    "**Tensor**与**ndarray**的最主要区别：Tensor可以在GPU上进行计算，可以自动求导。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 8.4490e-39, 7.7052e+31, 7.2148e+22],\n",
       "         [2.5226e-18, 2.5930e-09, 1.0299e-11, 7.7196e-10]],\n",
       "\n",
       "        [[2.6409e-06, 4.1429e-11, 4.2485e-05, 2.9573e-18],\n",
       "         [6.7333e+22, 1.7591e+22, 1.7184e+25, 4.3222e+27],\n",
       "         [6.1972e-04, 7.2443e+22, 1.7728e+28, 7.0367e+22]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x  = torch.Tensor(2,3,4) # torch.Tensor(shape) 创建出一个未初始化的Tensor\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.3839, 0.6207, 1.7443, 0.6530],\n",
      "         [0.4751, 0.6660, 0.9988, 0.2420],\n",
      "         [1.0407, 0.9756, 1.6424, 1.2415]],\n",
      "\n",
      "        [[0.4869, 1.0725, 0.6916, 1.0074],\n",
      "         [0.6294, 0.7366, 1.1275, 1.3891],\n",
      "         [0.9212, 1.5383, 1.4855, 0.8844]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2,3,4)\n",
    "b = torch.rand(2,3,4)\n",
    "\n",
    "x = torch.add(a,b)  # 使用Tensor()方法创建出来的Tensor用来接收计算结果，当然torch.add(..)也会返回计算结果的\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.3839, 0.6207, 1.7443, 0.6530],\n",
       "         [0.4751, 0.6660, 0.9988, 0.2420],\n",
       "         [1.0407, 0.9756, 1.6424, 1.2415]],\n",
       "\n",
       "        [[0.4869, 1.0725, 0.6916, 1.0074],\n",
       "         [0.6294, 0.7366, 1.1275, 1.3891],\n",
       "         [0.9212, 1.5383, 1.4855, 0.8844]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6759, 0.4646, 0.8829, 0.0632],\n",
       "         [0.2150, 0.3049, 0.5503, 0.1571],\n",
       "         [0.4024, 0.5474, 0.9509, 0.5834]],\n",
       "\n",
       "        [[0.2586, 0.7124, 0.1468, 0.0646],\n",
       "         [0.6201, 0.3861, 0.5532, 0.8023],\n",
       "         [0.5772, 0.9280, 0.6851, 0.4593]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.3839, 0.6207, 1.7443, 0.6530],\n",
       "         [0.4751, 0.6660, 0.9988, 0.2420],\n",
       "         [1.0407, 0.9756, 1.6424, 1.2415]],\n",
       "\n",
       "        [[0.4869, 1.0725, 0.6916, 1.0074],\n",
       "         [0.6294, 0.7366, 1.1275, 1.3891],\n",
       "         [0.9212, 1.5383, 1.4855, 0.8844]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.add_(b) # 所有带 _ 的operation，都会更改调用对象的值 a = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.3839, 0.6207, 1.7443, 0.6530],\n",
       "         [0.4751, 0.6660, 0.9988, 0.2420],\n",
       "         [1.0407, 0.9756, 1.6424, 1.2415]],\n",
       "\n",
       "        [[0.4869, 1.0725, 0.6916, 1.0074],\n",
       "         [0.6294, 0.7366, 1.1275, 1.3891],\n",
       "         [0.9212, 1.5383, 1.4855, 0.8844]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自动求导\n",
    "\n",
    "pytorch的自动求导工具包在torch.autograd中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.])\n",
      "tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2.0], requires_grad = True)\n",
    "a = torch.tensor([4.0], requires_grad = True)\n",
    "y = x * a\n",
    "\n",
    "y.backward()    \n",
    "\n",
    "print(x.grad)   # 2 * x = 4\n",
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "x_train = torch.rand(100)\n",
    "y_train = x_train * 2 + 3 # w = 2, b = 3, y = 2 * x + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor([0.0],requires_grad = True)\n",
    "b = torch.tensor([0.0],requires_grad = True)\n",
    "\n",
    "print(type(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre = x_train * w + b\n",
    "y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, w: 1.9950, b: 3.0028, training loss: 0.0000\n",
      "Iter: 10, w: 1.9951, b: 3.0027, training loss: 0.0000\n",
      "Iter: 20, w: 1.9952, b: 3.0027, training loss: 0.0000\n",
      "Iter: 30, w: 1.9952, b: 3.0026, training loss: 0.0000\n",
      "Iter: 40, w: 1.9953, b: 3.0026, training loss: 0.0000\n",
      "Iter: 50, w: 1.9954, b: 3.0025, training loss: 0.0000\n",
      "Iter: 60, w: 1.9955, b: 3.0025, training loss: 0.0000\n",
      "Iter: 70, w: 1.9956, b: 3.0025, training loss: 0.0000\n",
      "Iter: 80, w: 1.9956, b: 3.0024, training loss: 0.0000\n",
      "Iter: 90, w: 1.9957, b: 3.0024, training loss: 0.0000\n",
      "Iter: 100, w: 1.9958, b: 3.0023, training loss: 0.0000\n",
      "Iter: 110, w: 1.9959, b: 3.0023, training loss: 0.0000\n",
      "Iter: 120, w: 1.9959, b: 3.0022, training loss: 0.0000\n",
      "Iter: 130, w: 1.9960, b: 3.0022, training loss: 0.0000\n",
      "Iter: 140, w: 1.9961, b: 3.0022, training loss: 0.0000\n",
      "Iter: 150, w: 1.9962, b: 3.0021, training loss: 0.0000\n",
      "Iter: 160, w: 1.9962, b: 3.0021, training loss: 0.0000\n",
      "Iter: 170, w: 1.9963, b: 3.0021, training loss: 0.0000\n",
      "Iter: 180, w: 1.9964, b: 3.0020, training loss: 0.0000\n",
      "Iter: 190, w: 1.9964, b: 3.0020, training loss: 0.0000\n",
      "Iter: 200, w: 1.9965, b: 3.0019, training loss: 0.0000\n",
      "Iter: 210, w: 1.9965, b: 3.0019, training loss: 0.0000\n",
      "Iter: 220, w: 1.9966, b: 3.0019, training loss: 0.0000\n",
      "Iter: 230, w: 1.9967, b: 3.0018, training loss: 0.0000\n",
      "Iter: 240, w: 1.9967, b: 3.0018, training loss: 0.0000\n",
      "Iter: 250, w: 1.9968, b: 3.0018, training loss: 0.0000\n",
      "Iter: 260, w: 1.9968, b: 3.0018, training loss: 0.0000\n",
      "Iter: 270, w: 1.9969, b: 3.0017, training loss: 0.0000\n",
      "Iter: 280, w: 1.9970, b: 3.0017, training loss: 0.0000\n",
      "Iter: 290, w: 1.9970, b: 3.0017, training loss: 0.0000\n",
      "Iter: 300, w: 1.9971, b: 3.0016, training loss: 0.0000\n",
      "Iter: 310, w: 1.9971, b: 3.0016, training loss: 0.0000\n",
      "Iter: 320, w: 1.9972, b: 3.0016, training loss: 0.0000\n",
      "Iter: 330, w: 1.9972, b: 3.0015, training loss: 0.0000\n",
      "Iter: 340, w: 1.9973, b: 3.0015, training loss: 0.0000\n",
      "Iter: 350, w: 1.9973, b: 3.0015, training loss: 0.0000\n",
      "Iter: 360, w: 1.9974, b: 3.0015, training loss: 0.0000\n",
      "Iter: 370, w: 1.9974, b: 3.0014, training loss: 0.0000\n",
      "Iter: 380, w: 1.9975, b: 3.0014, training loss: 0.0000\n",
      "Iter: 390, w: 1.9975, b: 3.0014, training loss: 0.0000\n",
      "Iter: 400, w: 1.9975, b: 3.0014, training loss: 0.0000\n",
      "Iter: 410, w: 1.9976, b: 3.0013, training loss: 0.0000\n",
      "Iter: 420, w: 1.9976, b: 3.0013, training loss: 0.0000\n",
      "Iter: 430, w: 1.9977, b: 3.0013, training loss: 0.0000\n",
      "Iter: 440, w: 1.9977, b: 3.0013, training loss: 0.0000\n",
      "Iter: 450, w: 1.9978, b: 3.0012, training loss: 0.0000\n",
      "Iter: 460, w: 1.9978, b: 3.0012, training loss: 0.0000\n",
      "Iter: 470, w: 1.9978, b: 3.0012, training loss: 0.0000\n",
      "Iter: 480, w: 1.9979, b: 3.0012, training loss: 0.0000\n",
      "Iter: 490, w: 1.9979, b: 3.0012, training loss: 0.0000\n",
      "Iter: 500, w: 1.9979, b: 3.0011, training loss: 0.0000\n",
      "Iter: 510, w: 1.9980, b: 3.0011, training loss: 0.0000\n",
      "Iter: 520, w: 1.9980, b: 3.0011, training loss: 0.0000\n",
      "Iter: 530, w: 1.9980, b: 3.0011, training loss: 0.0000\n",
      "Iter: 540, w: 1.9981, b: 3.0011, training loss: 0.0000\n",
      "Iter: 550, w: 1.9981, b: 3.0010, training loss: 0.0000\n",
      "Iter: 560, w: 1.9982, b: 3.0010, training loss: 0.0000\n",
      "Iter: 570, w: 1.9982, b: 3.0010, training loss: 0.0000\n",
      "Iter: 580, w: 1.9982, b: 3.0010, training loss: 0.0000\n",
      "Iter: 590, w: 1.9982, b: 3.0010, training loss: 0.0000\n",
      "Iter: 600, w: 1.9983, b: 3.0010, training loss: 0.0000\n",
      "Iter: 610, w: 1.9983, b: 3.0009, training loss: 0.0000\n",
      "Iter: 620, w: 1.9983, b: 3.0009, training loss: 0.0000\n",
      "Iter: 630, w: 1.9984, b: 3.0009, training loss: 0.0000\n",
      "Iter: 640, w: 1.9984, b: 3.0009, training loss: 0.0000\n",
      "Iter: 650, w: 1.9984, b: 3.0009, training loss: 0.0000\n",
      "Iter: 660, w: 1.9985, b: 3.0009, training loss: 0.0000\n",
      "Iter: 670, w: 1.9985, b: 3.0008, training loss: 0.0000\n",
      "Iter: 680, w: 1.9985, b: 3.0008, training loss: 0.0000\n",
      "Iter: 690, w: 1.9985, b: 3.0008, training loss: 0.0000\n",
      "Iter: 700, w: 1.9986, b: 3.0008, training loss: 0.0000\n",
      "Iter: 710, w: 1.9986, b: 3.0008, training loss: 0.0000\n",
      "Iter: 720, w: 1.9986, b: 3.0008, training loss: 0.0000\n",
      "Iter: 730, w: 1.9986, b: 3.0008, training loss: 0.0000\n",
      "Iter: 740, w: 1.9987, b: 3.0007, training loss: 0.0000\n",
      "Iter: 750, w: 1.9987, b: 3.0007, training loss: 0.0000\n",
      "Iter: 760, w: 1.9987, b: 3.0007, training loss: 0.0000\n",
      "Iter: 770, w: 1.9987, b: 3.0007, training loss: 0.0000\n",
      "Iter: 780, w: 1.9987, b: 3.0007, training loss: 0.0000\n",
      "Iter: 790, w: 1.9988, b: 3.0007, training loss: 0.0000\n",
      "Iter: 800, w: 1.9988, b: 3.0007, training loss: 0.0000\n",
      "Iter: 810, w: 1.9988, b: 3.0007, training loss: 0.0000\n",
      "Iter: 820, w: 1.9988, b: 3.0006, training loss: 0.0000\n",
      "Iter: 830, w: 1.9989, b: 3.0006, training loss: 0.0000\n",
      "Iter: 840, w: 1.9989, b: 3.0006, training loss: 0.0000\n",
      "Iter: 850, w: 1.9989, b: 3.0006, training loss: 0.0000\n",
      "Iter: 860, w: 1.9989, b: 3.0006, training loss: 0.0000\n",
      "Iter: 870, w: 1.9989, b: 3.0006, training loss: 0.0000\n",
      "Iter: 880, w: 1.9990, b: 3.0006, training loss: 0.0000\n",
      "Iter: 890, w: 1.9990, b: 3.0006, training loss: 0.0000\n",
      "Iter: 900, w: 1.9990, b: 3.0006, training loss: 0.0000\n",
      "Iter: 910, w: 1.9990, b: 3.0006, training loss: 0.0000\n",
      "Iter: 920, w: 1.9990, b: 3.0005, training loss: 0.0000\n",
      "Iter: 930, w: 1.9990, b: 3.0005, training loss: 0.0000\n",
      "Iter: 940, w: 1.9991, b: 3.0005, training loss: 0.0000\n",
      "Iter: 950, w: 1.9991, b: 3.0005, training loss: 0.0000\n",
      "Iter: 960, w: 1.9991, b: 3.0005, training loss: 0.0000\n",
      "Iter: 970, w: 1.9991, b: 3.0005, training loss: 0.0000\n",
      "Iter: 980, w: 1.9991, b: 3.0005, training loss: 0.0000\n",
      "Iter: 990, w: 1.9991, b: 3.0005, training loss: 0.0000\n",
      "Iter: 1000, w: 1.9992, b: 3.0005, training loss: 0.0000\n",
      "Iter: 1010, w: 1.9992, b: 3.0005, training loss: 0.0000\n",
      "Iter: 1020, w: 1.9992, b: 3.0005, training loss: 0.0000\n",
      "Iter: 1030, w: 1.9992, b: 3.0004, training loss: 0.0000\n",
      "Iter: 1040, w: 1.9992, b: 3.0004, training loss: 0.0000\n",
      "Iter: 1050, w: 1.9992, b: 3.0004, training loss: 0.0000\n",
      "Iter: 1060, w: 1.9992, b: 3.0004, training loss: 0.0000\n",
      "Iter: 1070, w: 1.9993, b: 3.0004, training loss: 0.0000\n",
      "Iter: 1080, w: 1.9993, b: 3.0004, training loss: 0.0000\n",
      "Iter: 1090, w: 1.9993, b: 3.0004, training loss: 0.0000\n",
      "Iter: 1100, w: 1.9993, b: 3.0004, training loss: 0.0000\n",
      "Iter: 1110, w: 1.9993, b: 3.0004, training loss: 0.0000\n",
      "Iter: 1120, w: 1.9993, b: 3.0004, training loss: 0.0000\n",
      "Iter: 1130, w: 1.9993, b: 3.0004, training loss: 0.0000\n",
      "Iter: 1140, w: 1.9993, b: 3.0004, training loss: 0.0000\n",
      "Iter: 1150, w: 1.9993, b: 3.0004, training loss: 0.0000\n",
      "Iter: 1160, w: 1.9994, b: 3.0004, training loss: 0.0000\n",
      "Iter: 1170, w: 1.9994, b: 3.0003, training loss: 0.0000\n",
      "Iter: 1180, w: 1.9994, b: 3.0003, training loss: 0.0000\n",
      "Iter: 1190, w: 1.9994, b: 3.0003, training loss: 0.0000\n",
      "Iter: 1200, w: 1.9994, b: 3.0003, training loss: 0.0000\n",
      "Iter: 1210, w: 1.9994, b: 3.0003, training loss: 0.0000\n",
      "Iter: 1220, w: 1.9994, b: 3.0003, training loss: 0.0000\n",
      "Iter: 1230, w: 1.9994, b: 3.0003, training loss: 0.0000\n",
      "Iter: 1240, w: 1.9994, b: 3.0003, training loss: 0.0000\n",
      "Iter: 1250, w: 1.9995, b: 3.0003, training loss: 0.0000\n",
      "Iter: 1260, w: 1.9995, b: 3.0003, training loss: 0.0000\n",
      "Iter: 1270, w: 1.9995, b: 3.0003, training loss: 0.0000\n",
      "Iter: 1280, w: 1.9995, b: 3.0003, training loss: 0.0000\n",
      "Iter: 1290, w: 1.9995, b: 3.0003, training loss: 0.0000\n",
      "Iter: 1300, w: 1.9995, b: 3.0003, training loss: 0.0000\n",
      "Iter: 1310, w: 1.9995, b: 3.0003, training loss: 0.0000\n",
      "Iter: 1320, w: 1.9995, b: 3.0003, training loss: 0.0000\n",
      "Iter: 1330, w: 1.9995, b: 3.0003, training loss: 0.0000\n",
      "Iter: 1340, w: 1.9995, b: 3.0003, training loss: 0.0000\n",
      "Iter: 1350, w: 1.9995, b: 3.0003, training loss: 0.0000\n",
      "Iter: 1360, w: 1.9995, b: 3.0003, training loss: 0.0000\n",
      "Iter: 1370, w: 1.9996, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1380, w: 1.9996, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1390, w: 1.9996, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1400, w: 1.9996, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1410, w: 1.9996, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1420, w: 1.9996, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1430, w: 1.9996, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1440, w: 1.9996, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1450, w: 1.9996, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1460, w: 1.9996, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1470, w: 1.9996, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1480, w: 1.9996, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1490, w: 1.9996, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1500, w: 1.9996, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1510, w: 1.9997, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1520, w: 1.9997, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1530, w: 1.9997, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1540, w: 1.9997, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1550, w: 1.9997, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1560, w: 1.9997, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1570, w: 1.9997, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1580, w: 1.9997, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1590, w: 1.9997, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1600, w: 1.9997, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1610, w: 1.9997, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1620, w: 1.9997, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1630, w: 1.9997, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1640, w: 1.9997, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1650, w: 1.9997, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1660, w: 1.9997, b: 3.0002, training loss: 0.0000\n",
      "Iter: 1670, w: 1.9997, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1680, w: 1.9997, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1690, w: 1.9997, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1700, w: 1.9997, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1710, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1720, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1730, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1740, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1750, w: 1.9998, b: 3.0001, training loss: 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1760, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1770, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1780, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1790, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1800, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1810, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1820, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1830, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1840, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1850, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1860, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1870, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1880, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1890, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1900, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1910, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1920, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1930, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1940, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1950, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1960, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1970, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1980, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 1990, w: 1.9998, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2000, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2010, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2020, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2030, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2040, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2050, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2060, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2070, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2080, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2090, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2100, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2110, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2120, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2130, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2140, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2150, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2160, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2170, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2180, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2190, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2200, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2210, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2220, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2230, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2240, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2250, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2260, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2270, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2280, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2290, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2300, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2310, w: 1.9999, b: 3.0001, training loss: 0.0000\n",
      "Iter: 2320, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2330, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2340, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2350, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2360, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2370, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2380, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2390, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2400, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2410, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2420, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2430, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2440, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2450, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2460, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2470, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2480, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2490, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2500, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2510, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2520, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2530, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2540, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2550, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2560, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2570, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2580, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2590, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2600, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2610, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2620, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2630, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2640, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2650, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2660, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2670, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2680, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2690, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2700, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2710, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2720, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2730, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2740, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2750, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2760, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2770, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2780, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2790, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2800, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2810, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2820, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2830, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2840, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2850, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2860, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2870, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2880, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2890, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2900, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2910, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2920, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2930, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2940, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2950, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2960, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2970, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2980, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 2990, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3000, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3010, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3020, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3030, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3040, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3050, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3060, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3070, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3080, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3090, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3100, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3110, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3120, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3130, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3140, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3150, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3160, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3170, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3180, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3190, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3200, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3210, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3220, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3230, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3240, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3250, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3260, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3270, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3280, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3290, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3300, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3310, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3320, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3330, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3340, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3350, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3360, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3370, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3380, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3390, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3400, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3410, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3420, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3430, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3440, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3450, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3460, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3470, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3480, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3490, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3500, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3510, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3520, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3530, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3540, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3550, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3560, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3570, w: 1.9999, b: 3.0000, training loss: 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3580, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3590, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3600, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3610, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3620, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3630, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3640, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3650, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3660, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3670, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3680, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3690, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3700, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3710, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3720, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3730, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3740, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3750, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3760, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3770, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3780, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3790, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3800, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3810, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3820, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3830, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3840, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3850, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3860, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3870, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3880, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3890, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3900, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3910, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3920, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3930, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3940, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3950, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3960, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3970, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3980, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 3990, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4000, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4010, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4020, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4030, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4040, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4050, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4060, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4070, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4080, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4090, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4100, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4110, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4120, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4130, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4140, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4150, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4160, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4170, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4180, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4190, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4200, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4210, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4220, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4230, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4240, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4250, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4260, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4270, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4280, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4290, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4300, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4310, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4320, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4330, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4340, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4350, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4360, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4370, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4380, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4390, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4400, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4410, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4420, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4430, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4440, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4450, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4460, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4470, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4480, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4490, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4500, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4510, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4520, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4530, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4540, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4550, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4560, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4570, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4580, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4590, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4600, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4610, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4620, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4630, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4640, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4650, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4660, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4670, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4680, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4690, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4700, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4710, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4720, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4730, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4740, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4750, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4760, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4770, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4780, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4790, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4800, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4810, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4820, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4830, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4840, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4850, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4860, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4870, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4880, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4890, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4900, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4910, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4920, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4930, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4940, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4950, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4960, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4970, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4980, w: 1.9999, b: 3.0000, training loss: 0.0000\n",
      "Iter: 4990, w: 1.9999, b: 3.0000, training loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "lr = 0.015\n",
    "loss_func = torch.nn.MSELoss()\n",
    "for i in range(5000):\n",
    "    y_pre = x_train * w + b\n",
    "\n",
    "    loss = loss_func(y_train, y_pre)\n",
    "    if i % 10 == 0:\n",
    "        print(\"Iter: %d, w: %.4f, b: %.4f, training loss: %.4f\" % (i, w.item(), b.item(), loss.item()))\n",
    "    loss.backward()\n",
    "    \n",
    "    w.data -= w.grad * lr\n",
    "    b.data -= b.grad * lr\n",
    "    \n",
    "    w.grad.data.zero_()\n",
    "    b.grad.data.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
