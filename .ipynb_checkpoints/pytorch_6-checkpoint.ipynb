{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型轻量化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogVsCatDataset(Dataset):\n",
    "    def __init__(self, data_path, train=True, transform=None):\n",
    "        self.data_path=data_path\n",
    "        self.img_path = []\n",
    "        self.label = []\n",
    "        self.train = train\n",
    "        if train:\n",
    "            img_path_names = os.listdir(os.path.join(self.data_path, 'train'))\n",
    "            for img_path_name in img_path_names:\n",
    "                temp_list = os.listdir(os.path.join(self.data_path, 'train', img_path_name))\n",
    "                self.img_path.extend(temp_list)\n",
    "                if img_path_name == 'cat':\n",
    "                    self.label.extend([0]*len(temp_list))\n",
    "                elif img_path_name == 'dog':\n",
    "                    self.label.extend([1]*len(temp_list))\n",
    "        else:\n",
    "            img_path_names = os.listdir(os.path.join(self.data_path, 'val'))\n",
    "            for img_path_name in img_path_names:\n",
    "                temp_list = os.listdir(os.path.join(self.data_path, 'val', img_path_name))\n",
    "                self.img_path.extend(temp_list)\n",
    "                if img_path_name == 'cat':\n",
    "                    self.label.extend([0]*len(temp_list))\n",
    "                elif img_path_name == 'dog':\n",
    "                    self.label.extend([1]*len(temp_list))\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label = self.label[idx]\n",
    "        img_type = 'cat' if label == 0 else 'dog'\n",
    "        model_type = 'train' if self.train else 'val'\n",
    "        if self.train:\n",
    "            image = Image.open(os.path.join(self.data_path, model_type, img_type, self.img_path[idx]))\n",
    "        else:\n",
    "            image = Image.open(os.path.join(self.data_path, model_type, img_type, self.img_path[idx]))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = torch.from_numpy(np.array(label))\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = DogVsCatDataset(\n",
    "                        data_path = r'D:\\泰迪智能科技有限公司\\09课程\\02案例课程\\03 计算机视觉案例\\图像分类\\猫狗大战\\demo',\n",
    "                        train=False,\n",
    "                        transform = transforms.Compose([          \n",
    "                                        transforms.Resize([150, 150]),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                             std=[0.229, 0.224, 0.225])]))\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()  # 声明验证函数，禁止所有梯度进行更新\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    # 强制后面的计算不生成计算图，加快测试效率\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target.long(), reduction='sum').item()  # 对每个batch的loss进行求和\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print('\\nTest: average loss: {:.4f}, accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, 1)\n",
    "        self.max_pool = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.line1 = nn.Linear(18496, 512)\n",
    "        self.line2 = nn.Linear(512, 128)\n",
    "        self.line3 = nn.Linear(128, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.line1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.line2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.line3(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNNModel()\n",
    "parms = torch.load('cnn_model_parms.pth')\n",
    "model.load_state_dict(parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件大小:\n",
      "\t38241888字节\n",
      "\t36.47M\n"
     ]
    }
   ],
   "source": [
    "file_size = os.path.getsize('cnn_model_parms.pth')\n",
    "print('文件大小:\\n\\t{}字节\\n\\t{}M'.format(file_size, round(file_size/1024**2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 148, 148]             448\n",
      "         MaxPool2d-2           [-1, 16, 74, 74]               0\n",
      "              ReLU-3           [-1, 16, 74, 74]               0\n",
      "            Conv2d-4           [-1, 32, 72, 72]           4,640\n",
      "         MaxPool2d-5           [-1, 32, 36, 36]               0\n",
      "              ReLU-6           [-1, 32, 36, 36]               0\n",
      "            Conv2d-7           [-1, 64, 34, 34]          18,496\n",
      "         MaxPool2d-8           [-1, 64, 17, 17]               0\n",
      "              ReLU-9           [-1, 64, 17, 17]               0\n",
      "          Flatten-10                [-1, 18496]               0\n",
      "           Linear-11                  [-1, 512]       9,470,464\n",
      "             ReLU-12                  [-1, 512]               0\n",
      "          Dropout-13                  [-1, 512]               0\n",
      "           Linear-14                  [-1, 128]          65,664\n",
      "             ReLU-15                  [-1, 128]               0\n",
      "          Dropout-16                  [-1, 128]               0\n",
      "           Linear-17                    [-1, 2]             258\n",
      "================================================================\n",
      "Total params: 9,559,970\n",
      "Trainable params: 9,559,970\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.26\n",
      "Forward/backward pass size (MB): 6.91\n",
      "Params size (MB): 36.47\n",
      "Estimated Total Size (MB): 43.64\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model.to('cuda'), (3, 150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: average loss: 0.5234, accuracy: 2063/2500 (83%)\n",
      "Cost: 5.509939432144165\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "test(model, 'cuda', test_loader)\n",
    "end = time.time()\n",
    "print('Cost:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型剪枝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 层剪枝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color='red'>将每层中较小的权重置零"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_prune(model, pruning_perc):\n",
    "    '''\n",
    "    Prune pruning_perc % weights layer-wise\n",
    "    '''\n",
    "    threshold_list = []\n",
    "    for p in model.parameters():\n",
    "        if len(p.data.size()) != 1: # bias\n",
    "            weight = p.cpu().data.abs().numpy().flatten()\n",
    "            threshold = np.percentile(weight, pruning_perc)\n",
    "            threshold_list.append(threshold)\n",
    "\n",
    "    # generate mask\n",
    "    masks = []\n",
    "    idx = 0\n",
    "    for p in model.parameters():\n",
    "        if len(p.data.size()) != 1:\n",
    "            pruned_inds = p.data.abs() > threshold_list[idx]\n",
    "            masks.append(pruned_inds.float())\n",
    "            idx += 1\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "pruned_model = deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = weight_prune(pruned_model, 80)  # 剪枝60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weight_layer_name = [i for i in list(parms.keys()) if 'weight' in i]\n",
    "for i in range(len(weight_layer_name)):\n",
    "    parms[weight_layer_name[i]] *= mask[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_model.load_state_dict(parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.weight',\n",
       "              tensor([[[[-0.0000,  0.0000, -0.0000],\n",
       "                        [-0.0000, -0.0000, -0.0000],\n",
       "                        [-0.5159, -0.0000, -0.5250]],\n",
       "              \n",
       "                       [[ 0.0000,  0.4308, -0.0000],\n",
       "                        [-0.0000, -0.0000,  0.0000],\n",
       "                        [-0.0000, -0.0000, -0.4818]],\n",
       "              \n",
       "                       [[ 0.6757,  0.7788,  0.4527],\n",
       "                        [ 0.0000,  0.6251,  0.0000],\n",
       "                        [-0.0000, -0.0000, -0.0000]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0000, -0.6090, -0.5513],\n",
       "                        [ 0.0000,  0.0000,  0.0000],\n",
       "                        [ 0.4241,  0.6808,  0.4858]],\n",
       "              \n",
       "                       [[-0.0000, -0.4679, -0.4809],\n",
       "                        [ 0.0000,  0.0000,  0.0000],\n",
       "                        [ 0.0000,  0.0000,  0.0000]],\n",
       "              \n",
       "                       [[ 0.0000, -0.0000, -0.4427],\n",
       "                        [ 0.0000, -0.0000, -0.0000],\n",
       "                        [ 0.0000,  0.0000, -0.0000]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0000,  0.0000,  0.0000],\n",
       "                        [-0.0000,  0.0000, -0.0000],\n",
       "                        [-0.0000, -0.0000, -0.0000]],\n",
       "              \n",
       "                       [[-0.0000,  0.0000, -0.0000],\n",
       "                        [-0.0000, -0.0000, -0.5599],\n",
       "                        [-0.5796, -0.5549, -0.4309]],\n",
       "              \n",
       "                       [[ 0.0000,  0.0000,  0.0000],\n",
       "                        [-0.0000,  0.0000, -0.0000],\n",
       "                        [-0.0000,  0.0000, -0.0000]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0000,  0.0000,  0.0000],\n",
       "                        [-0.5023,  0.0000,  0.0000],\n",
       "                        [-0.4582,  0.0000,  0.5328]],\n",
       "              \n",
       "                       [[-0.0000,  0.0000, -0.0000],\n",
       "                        [-0.5076,  0.0000,  0.0000],\n",
       "                        [-0.5699,  0.0000,  0.0000]],\n",
       "              \n",
       "                       [[-0.0000,  0.0000,  0.0000],\n",
       "                        [-0.6218,  0.0000,  0.0000],\n",
       "                        [-0.5410,  0.0000,  0.0000]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0000,  0.4580,  0.0000],\n",
       "                        [-0.0000,  0.0000,  0.0000],\n",
       "                        [-0.0000, -0.4405, -0.0000]],\n",
       "              \n",
       "                       [[-0.0000,  0.0000,  0.0000],\n",
       "                        [-0.0000, -0.0000,  0.0000],\n",
       "                        [-0.0000, -0.4615,  0.0000]],\n",
       "              \n",
       "                       [[ 0.0000,  0.4595,  0.0000],\n",
       "                        [-0.4649,  0.0000,  0.0000],\n",
       "                        [-0.0000, -0.4130, -0.0000]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0000,  0.6707,  0.0000],\n",
       "                        [ 0.0000, -0.0000, -0.4399],\n",
       "                        [-0.0000, -0.5766, -0.0000]],\n",
       "              \n",
       "                       [[ 0.4292,  0.7122,  0.0000],\n",
       "                        [ 0.0000,  0.0000, -0.0000],\n",
       "                        [-0.0000, -0.4820,  0.0000]],\n",
       "              \n",
       "                       [[-0.0000,  0.0000, -0.0000],\n",
       "                        [ 0.0000, -0.0000, -0.4562],\n",
       "                        [-0.0000, -0.4856, -0.0000]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0000,  0.4335,  0.0000],\n",
       "                        [ 0.0000,  0.0000,  0.0000],\n",
       "                        [-0.0000, -0.0000, -0.0000]],\n",
       "              \n",
       "                       [[ 0.0000,  0.0000, -0.0000],\n",
       "                        [-0.0000,  0.0000, -0.0000],\n",
       "                        [-0.0000, -0.4325, -0.0000]],\n",
       "              \n",
       "                       [[ 0.0000,  0.0000,  0.0000],\n",
       "                        [ 0.0000,  0.0000, -0.0000],\n",
       "                        [-0.0000, -0.0000,  0.0000]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0000,  0.0000, -0.0000],\n",
       "                        [ 0.0000,  0.4141, -0.4209],\n",
       "                        [ 0.0000,  0.0000, -0.5553]],\n",
       "              \n",
       "                       [[ 0.0000,  0.0000, -0.0000],\n",
       "                        [ 0.0000,  0.5787, -0.4404],\n",
       "                        [ 0.5303,  0.0000, -0.0000]],\n",
       "              \n",
       "                       [[-0.0000,  0.0000, -0.4699],\n",
       "                        [ 0.0000,  0.0000, -0.6960],\n",
       "                        [ 0.0000,  0.0000, -0.0000]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0000,  0.0000,  0.0000],\n",
       "                        [-0.0000,  0.0000,  0.0000],\n",
       "                        [-0.0000,  0.0000,  0.0000]],\n",
       "              \n",
       "                       [[ 0.0000,  0.0000,  0.0000],\n",
       "                        [ 0.0000,  0.0000,  0.5129],\n",
       "                        [ 0.0000,  0.0000,  0.0000]],\n",
       "              \n",
       "                       [[-0.0000, -0.0000,  0.0000],\n",
       "                        [ 0.0000,  0.0000, -0.0000],\n",
       "                        [-0.0000,  0.0000,  0.0000]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0000,  0.4807,  0.6718],\n",
       "                        [-0.0000,  0.0000,  0.0000],\n",
       "                        [ 0.0000, -0.0000, -0.0000]],\n",
       "              \n",
       "                       [[-0.5229,  0.0000,  0.0000],\n",
       "                        [-0.5468, -0.0000,  0.0000],\n",
       "                        [-0.6570, -0.4115, -0.5760]],\n",
       "              \n",
       "                       [[ 0.0000,  0.0000,  0.5632],\n",
       "                        [-0.0000,  0.0000,  0.5351],\n",
       "                        [-0.0000,  0.0000,  0.0000]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0000, -0.0000, -0.0000],\n",
       "                        [ 0.0000, -0.0000, -0.0000],\n",
       "                        [ 0.0000,  0.0000,  0.0000]],\n",
       "              \n",
       "                       [[-0.0000, -0.0000, -0.0000],\n",
       "                        [ 0.0000,  0.0000,  0.0000],\n",
       "                        [ 0.0000,  0.0000,  0.0000]],\n",
       "              \n",
       "                       [[-0.0000, -0.0000, -0.0000],\n",
       "                        [-0.0000, -0.0000,  0.0000],\n",
       "                        [ 0.0000, -0.0000, -0.0000]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.4919, -0.7084,  0.0000],\n",
       "                        [-0.4351,  0.0000,  0.5346],\n",
       "                        [ 0.0000,  0.4520,  0.0000]],\n",
       "              \n",
       "                       [[-0.0000, -0.0000,  0.0000],\n",
       "                        [-0.0000,  0.0000,  0.5502],\n",
       "                        [ 0.0000,  0.4938,  0.0000]],\n",
       "              \n",
       "                       [[-0.0000, -0.6205,  0.0000],\n",
       "                        [-0.0000, -0.0000,  0.0000],\n",
       "                        [ 0.0000,  0.0000, -0.0000]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.5177,  0.4488, -0.0000],\n",
       "                        [ 0.5934,  0.0000,  0.0000],\n",
       "                        [ 0.5388,  0.4690,  0.0000]],\n",
       "              \n",
       "                       [[-0.0000, -0.0000, -0.0000],\n",
       "                        [-0.0000, -0.0000, -0.0000],\n",
       "                        [-0.0000, -0.0000, -0.0000]],\n",
       "              \n",
       "                       [[-0.0000, -0.0000,  0.0000],\n",
       "                        [-0.0000, -0.0000, -0.0000],\n",
       "                        [-0.0000, -0.0000,  0.0000]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0000,  0.4180, -0.0000],\n",
       "                        [ 0.0000, -0.0000, -0.0000],\n",
       "                        [-0.0000, -0.0000,  0.0000]],\n",
       "              \n",
       "                       [[ 0.0000,  0.6100, -0.0000],\n",
       "                        [ 0.0000, -0.0000, -0.0000],\n",
       "                        [ 0.0000,  0.0000,  0.0000]],\n",
       "              \n",
       "                       [[ 0.0000,  0.0000, -0.0000],\n",
       "                        [-0.0000, -0.0000, -0.0000],\n",
       "                        [ 0.0000, -0.0000, -0.0000]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0000, -0.0000, -0.0000],\n",
       "                        [-0.0000, -0.0000, -0.0000],\n",
       "                        [-0.0000,  0.0000,  0.4904]],\n",
       "              \n",
       "                       [[ 0.0000,  0.0000, -0.0000],\n",
       "                        [ 0.0000, -0.5059, -0.0000],\n",
       "                        [ 0.0000,  0.0000,  0.5471]],\n",
       "              \n",
       "                       [[ 0.0000,  0.0000, -0.0000],\n",
       "                        [-0.0000, -0.5960, -0.0000],\n",
       "                        [-0.0000,  0.0000,  0.0000]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0000,  0.0000,  0.0000],\n",
       "                        [-0.0000,  0.7089, -0.0000],\n",
       "                        [ 0.0000,  0.0000, -0.0000]],\n",
       "              \n",
       "                       [[-0.4366,  0.0000,  0.0000],\n",
       "                        [ 0.0000,  0.6652, -0.0000],\n",
       "                        [ 0.0000,  0.0000, -0.5924]],\n",
       "              \n",
       "                       [[-0.0000,  0.0000,  0.0000],\n",
       "                        [ 0.0000,  0.5699, -0.4189],\n",
       "                        [ 0.0000, -0.0000, -0.5015]]]], device='cuda:0')),\n",
       "             ('conv1.bias',\n",
       "              tensor([-0.9713, -0.3883, -1.2624, -0.3724, -0.4426, -0.1718, -0.1973, -0.3515,\n",
       "                      -1.2605, -0.5801, -0.3133, -0.3745, -0.5311, -0.1649, -0.1789, -0.2380],\n",
       "                     device='cuda:0')),\n",
       "             ('conv2.weight',\n",
       "              tensor([[[[-0.1579,  0.0000,  0.0000],\n",
       "                        [ 0.0000,  0.1885,  0.0000],\n",
       "                        [-0.0000, -0.1805, -0.0000]],\n",
       "              \n",
       "                       [[ 0.2839,  0.1788,  0.0000],\n",
       "                        [-0.0000, -0.0000, -0.2260],\n",
       "                        [-0.2755, -0.1847, -0.2891]],\n",
       "              \n",
       "                       [[-0.0000, -0.0000, -0.2361],\n",
       "                        [ 0.0000,  0.0000, -0.0000],\n",
       "                        [ 0.0000, -0.0000,  0.0000]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0000, -0.0000,  0.0000],\n",
       "                        [-0.0000,  0.0000,  0.0000],\n",
       "                        [-0.0000, -0.0000, -0.0000]],\n",
       "              \n",
       "                       [[ 0.0000, -0.0000,  0.0000],\n",
       "                        [-0.0000,  0.0000, -0.0000],\n",
       "                        [-0.0000, -0.0000, -0.0000]],\n",
       "              \n",
       "                       [[-0.0000,  0.0000, -0.0000],\n",
       "                        [-0.0000,  0.0000, -0.0000],\n",
       "                        [-0.0000,  0.0000, -0.0000]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2799, -0.1629, -0.0000],\n",
       "                        [-0.2207, -0.0000,  0.0000],\n",
       "                        [-0.3647,  0.0000, -0.0000]],\n",
       "              \n",
       "                       [[ 0.0000, -0.0000,  0.0000],\n",
       "                        [-0.0000, -0.0000,  0.0000],\n",
       "                        [ 0.0000, -0.0000, -0.0000]],\n",
       "              \n",
       "                       [[ 0.0000,  0.0000,  0.0000],\n",
       "                        [-0.0000,  0.0000, -0.0000],\n",
       "                        [-0.0000,  0.0000, -0.2630]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1794, -0.0000, -0.0000],\n",
       "                        [ 0.0000,  0.0000, -0.0000],\n",
       "                        [ 0.1940, -0.0000, -0.0000]],\n",
       "              \n",
       "                       [[-0.0000,  0.0000, -0.0000],\n",
       "                        [-0.0000,  0.0000, -0.0000],\n",
       "                        [-0.0000,  0.0000, -0.0000]],\n",
       "              \n",
       "                       [[ 0.0000, -0.0000, -0.0000],\n",
       "                        [ 0.3678, -0.2772, -0.0000],\n",
       "                        [ 0.2540, -0.1847, -0.0000]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0000,  0.0000, -0.0000],\n",
       "                        [ 0.0000,  0.0000,  0.0000],\n",
       "                        [ 0.0000, -0.0000, -0.0000]],\n",
       "              \n",
       "                       [[-0.1841, -0.0000, -0.0000],\n",
       "                        [ 0.0000, -0.0000, -0.1679],\n",
       "                        [ 0.0000,  0.0000,  0.0000]],\n",
       "              \n",
       "                       [[-0.2559, -0.2384, -0.3461],\n",
       "                        [ 0.0000,  0.0000, -0.0000],\n",
       "                        [ 0.3479,  0.1694, -0.0000]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0000, -0.0000,  0.0000],\n",
       "                        [-0.1873,  0.0000,  0.0000],\n",
       "                        [-0.0000, -0.0000, -0.0000]],\n",
       "              \n",
       "                       [[ 0.0000, -0.0000, -0.0000],\n",
       "                        [-0.0000, -0.0000, -0.0000],\n",
       "                        [-0.0000,  0.0000,  0.0000]],\n",
       "              \n",
       "                       [[-0.0000, -0.1627, -0.0000],\n",
       "                        [-0.1606, -0.0000, -0.0000],\n",
       "                        [ 0.0000, -0.0000, -0.0000]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0000,  0.0000,  0.0000],\n",
       "                        [-0.0000,  0.0000, -0.0000],\n",
       "                        [ 0.0000, -0.0000,  0.0000]],\n",
       "              \n",
       "                       [[ 0.0000, -0.0000, -0.1997],\n",
       "                        [ 0.0000, -0.1816, -0.0000],\n",
       "                        [-0.0000,  0.0000, -0.0000]],\n",
       "              \n",
       "                       [[ 0.1912,  0.0000, -0.0000],\n",
       "                        [-0.0000, -0.0000, -0.0000],\n",
       "                        [-0.0000,  0.0000, -0.1569]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0000, -0.0000,  0.0000],\n",
       "                        [-0.0000,  0.0000, -0.0000],\n",
       "                        [ 0.0000, -0.0000, -0.0000]],\n",
       "              \n",
       "                       [[ 0.2489, -0.0000, -0.0000],\n",
       "                        [-0.0000,  0.0000,  0.0000],\n",
       "                        [ 0.0000,  0.0000, -0.0000]],\n",
       "              \n",
       "                       [[-0.1846,  0.0000, -0.0000],\n",
       "                        [ 0.2800,  0.2092, -0.0000],\n",
       "                        [ 0.1803, -0.1771,  0.0000]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0000,  0.0000,  0.0000],\n",
       "                        [-0.0000, -0.0000, -0.0000],\n",
       "                        [-0.0000, -0.1810, -0.3193]],\n",
       "              \n",
       "                       [[ 0.0000,  0.0000, -0.0000],\n",
       "                        [-0.2284,  0.0000, -0.0000],\n",
       "                        [ 0.3587,  0.0000, -0.3630]],\n",
       "              \n",
       "                       [[-0.2497, -0.1834, -0.3467],\n",
       "                        [-0.2729, -0.3231, -0.2733],\n",
       "                        [-0.0000, -0.3422, -0.3098]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0000,  0.0000, -0.0000],\n",
       "                        [ 0.0000,  0.0000, -0.1971],\n",
       "                        [-0.0000, -0.1613,  0.1572]],\n",
       "              \n",
       "                       [[-0.0000,  0.0000, -0.0000],\n",
       "                        [ 0.0000,  0.3478, -0.1939],\n",
       "                        [ 0.2883, -0.0000, -0.0000]],\n",
       "              \n",
       "                       [[ 0.0000,  0.0000, -0.1818],\n",
       "                        [ 0.2161, -0.1741, -0.0000],\n",
       "                        [-0.0000,  0.2628,  0.0000]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1633,  0.0000,  0.1777],\n",
       "                        [-0.0000, -0.0000, -0.0000],\n",
       "                        [ 0.0000,  0.0000, -0.0000]],\n",
       "              \n",
       "                       [[ 0.1779, -0.1737, -0.0000],\n",
       "                        [ 0.2686,  0.3056, -0.0000],\n",
       "                        [-0.2783,  0.0000,  0.0000]],\n",
       "              \n",
       "                       [[ 0.0000,  0.2095,  0.2223],\n",
       "                        [-0.2070, -0.0000,  0.0000],\n",
       "                        [-0.0000, -0.2306, -0.0000]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0000,  0.0000,  0.0000],\n",
       "                        [ 0.0000,  0.0000, -0.0000],\n",
       "                        [-0.0000,  0.0000,  0.0000]],\n",
       "              \n",
       "                       [[ 0.0000,  0.0000,  0.0000],\n",
       "                        [ 0.0000, -0.0000, -0.0000],\n",
       "                        [-0.0000,  0.0000,  0.0000]],\n",
       "              \n",
       "                       [[-0.0000, -0.0000, -0.0000],\n",
       "                        [-0.0000,  0.0000, -0.0000],\n",
       "                        [-0.1579,  0.0000,  0.0000]]]], device='cuda:0')),\n",
       "             ('conv2.bias',\n",
       "              tensor([-0.6041,  0.0026, -0.3340, -0.0035, -0.0544, -0.2286, -0.0838, -0.1342,\n",
       "                      -0.1753, -0.1831, -0.0153, -0.0203, -0.0071, -0.0945, -0.1046, -0.8668,\n",
       "                      -0.1788, -0.1928, -0.1135, -0.2676,  0.1990,  0.0720, -0.3282,  0.0033,\n",
       "                      -0.1151, -0.4342, -0.3150,  0.0184, -0.1267, -0.0289, -0.1704, -0.3299],\n",
       "                     device='cuda:0')),\n",
       "             ('conv3.weight',\n",
       "              tensor([[[[ 0.1133, -0.0000, -0.0000],\n",
       "                        [ 0.1846,  0.0000,  0.0000],\n",
       "                        [ 0.0000,  0.0000, -0.0000]],\n",
       "              \n",
       "                       [[-0.0000, -0.0000, -0.0000],\n",
       "                        [-0.0000,  0.0000, -0.0000],\n",
       "                        [-0.0000, -0.0000, -0.0000]],\n",
       "              \n",
       "                       [[-0.0000, -0.0000, -0.0995],\n",
       "                        [ 0.1369, -0.0000, -0.1237],\n",
       "                        [-0.0000, -0.1064, -0.0000]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0000, -0.0000, -0.0000],\n",
       "                        [ 0.1413, -0.0000, -0.0000],\n",
       "                        [-0.0000, -0.0000, -0.0000]],\n",
       "              \n",
       "                       [[-0.0000, -0.0000, -0.0000],\n",
       "                        [-0.0000, -0.0000,  0.0000],\n",
       "                        [-0.0000, -0.0000,  0.0000]],\n",
       "              \n",
       "                       [[ 0.0000, -0.0000,  0.0000],\n",
       "                        [ 0.0000,  0.0000, -0.0000],\n",
       "                        [-0.0000, -0.0000, -0.0000]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0000,  0.1492, -0.0000],\n",
       "                        [-0.1222, -0.0000, -0.0000],\n",
       "                        [-0.0000,  0.0000,  0.1634]],\n",
       "              \n",
       "                       [[-0.0000, -0.0000, -0.0000],\n",
       "                        [-0.0000, -0.0000,  0.0000],\n",
       "                        [ 0.0000,  0.0000, -0.1199]],\n",
       "              \n",
       "                       [[-0.2234, -0.0000, -0.3691],\n",
       "                        [-0.1813,  0.2684,  0.0000],\n",
       "                        [-0.1954, -0.2344, -0.0000]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0000, -0.0000, -0.0000],\n",
       "                        [ 0.0000,  0.0000, -0.0000],\n",
       "                        [-0.0000,  0.0000,  0.0000]],\n",
       "              \n",
       "                       [[-0.0000, -0.0000, -0.0000],\n",
       "                        [-0.0000, -0.0000, -0.0000],\n",
       "                        [ 0.0000, -0.0000, -0.0000]],\n",
       "              \n",
       "                       [[-0.0000, -0.0000,  0.0000],\n",
       "                        [-0.0000, -0.0000,  0.0000],\n",
       "                        [-0.0000, -0.1086,  0.0000]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0000, -0.1002, -0.1025],\n",
       "                        [ 0.0000,  0.0000, -0.1154],\n",
       "                        [-0.0000, -0.0000, -0.0000]],\n",
       "              \n",
       "                       [[ 0.2131,  0.5734, -0.0000],\n",
       "                        [ 0.0000, -0.2088, -0.0000],\n",
       "                        [-0.1419, -0.1264,  0.0000]],\n",
       "              \n",
       "                       [[-0.1665, -0.0000, -0.0000],\n",
       "                        [-0.1276,  0.0000, -0.0000],\n",
       "                        [-0.0000,  0.1038, -0.1374]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1720, -0.0000, -0.0000],\n",
       "                        [ 0.0000, -0.0000, -0.0000],\n",
       "                        [-0.0000, -0.0000, -0.0000]],\n",
       "              \n",
       "                       [[ 0.1148,  0.1115, -0.1064],\n",
       "                        [ 0.1513, -0.0000, -0.2082],\n",
       "                        [ 0.0000, -0.1434, -0.1754]],\n",
       "              \n",
       "                       [[ 0.0000, -0.0000, -0.1223],\n",
       "                        [ 0.0000, -0.0000, -0.1135],\n",
       "                        [ 0.0000,  0.0000, -0.0000]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0000, -0.1158, -0.0000],\n",
       "                        [-0.0000, -0.1769, -0.1056],\n",
       "                        [-0.0000, -0.1559, -0.1379]],\n",
       "              \n",
       "                       [[ 0.0000,  0.0000, -0.0000],\n",
       "                        [ 0.0000,  0.0000, -0.0000],\n",
       "                        [ 0.1621,  0.0000,  0.2148]],\n",
       "              \n",
       "                       [[-0.0000,  0.0000, -0.0000],\n",
       "                        [-0.1271,  0.1667,  0.1423],\n",
       "                        [-0.2487, -0.0000,  0.0000]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1127, -0.0000, -0.0000],\n",
       "                        [ 0.0000,  0.0000, -0.0000],\n",
       "                        [ 0.0000,  0.2458,  0.1698]],\n",
       "              \n",
       "                       [[-0.0000, -0.2102, -0.3809],\n",
       "                        [-0.0000, -0.0000, -0.3505],\n",
       "                        [ 0.1028,  0.2687,  0.0000]],\n",
       "              \n",
       "                       [[-0.0000,  0.0000, -0.1198],\n",
       "                        [-0.1370,  0.1434, -0.0000],\n",
       "                        [-0.0000,  0.0000, -0.0000]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0000, -0.0000,  0.0000],\n",
       "                        [-0.0000, -0.0000, -0.0000],\n",
       "                        [ 0.0000, -0.0000, -0.0000]],\n",
       "              \n",
       "                       [[-0.0000, -0.0000, -0.0000],\n",
       "                        [-0.1096, -0.0000, -0.0000],\n",
       "                        [-0.0000, -0.1047, -0.0000]],\n",
       "              \n",
       "                       [[-0.0000, -0.0000,  0.1476],\n",
       "                        [ 0.0000, -0.0000, -0.0000],\n",
       "                        [-0.0000, -0.0000, -0.1505]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0000, -0.1004, -0.0000],\n",
       "                        [-0.0000, -0.0000, -0.1231],\n",
       "                        [-0.0000, -0.0000, -0.1042]],\n",
       "              \n",
       "                       [[-0.1083, -0.0000, -0.1682],\n",
       "                        [-0.1566, -0.1801, -0.0000],\n",
       "                        [-0.1229, -0.1628, -0.0000]],\n",
       "              \n",
       "                       [[-0.1023, -0.0000, -0.0000],\n",
       "                        [-0.0000, -0.0000, -0.0000],\n",
       "                        [-0.1417, -0.1403, -0.0000]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1533,  0.0000, -0.0992],\n",
       "                        [ 0.0000, -0.0000, -0.1353],\n",
       "                        [-0.1122,  0.0000,  0.0000]],\n",
       "              \n",
       "                       [[-0.0000, -0.0000,  0.0000],\n",
       "                        [ 0.0000,  0.1135,  0.0000],\n",
       "                        [-0.0000, -0.1745, -0.1019]],\n",
       "              \n",
       "                       [[-0.1909,  0.0000, -0.1069],\n",
       "                        [-0.0993, -0.0000, -0.0000],\n",
       "                        [-0.0000, -0.0000, -0.1202]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0000,  0.1542, -0.0000],\n",
       "                        [-0.1154, -0.0000,  0.0000],\n",
       "                        [-0.1510, -0.1246,  0.2517]],\n",
       "              \n",
       "                       [[ 0.1481,  0.1664, -0.1162],\n",
       "                        [-0.3339,  0.3319,  0.4084],\n",
       "                        [-0.5438, -0.2955,  0.0000]],\n",
       "              \n",
       "                       [[-0.0000, -0.0000, -0.0000],\n",
       "                        [-0.1094, -0.1118,  0.1267],\n",
       "                        [-0.2223,  0.0000,  0.0000]]]], device='cuda:0')),\n",
       "             ('conv3.bias',\n",
       "              tensor([-0.0725, -0.3979, -0.3194, -0.3041, -0.0596, -0.4811, -0.4721, -0.1746,\n",
       "                       0.2450, -0.1783, -0.1821, -0.1177, -0.4370, -0.2942, -0.0904,  0.0006,\n",
       "                      -0.1683, -0.1283, -0.0073, -0.2035, -0.3477, -0.2748, -0.1964, -0.0360,\n",
       "                       0.1725, -0.1999, -0.0575, -0.2710, -0.0161, -0.0532, -0.0019,  0.5662,\n",
       "                      -0.6356, -0.0707, -0.3554, -0.0836, -0.0580, -0.2645, -0.1490, -0.1631,\n",
       "                      -0.2515, -0.1156, -0.2869, -0.1130, -0.2321, -0.1653, -0.1667, -0.0956,\n",
       "                      -0.3719, -0.3331, -0.1981, -0.0691, -0.2295, -0.2471, -0.0482, -0.0925,\n",
       "                      -0.0051, -0.0443, -0.1417, -0.2760, -0.3240, -0.2009, -0.0154, -0.1478],\n",
       "                     device='cuda:0')),\n",
       "             ('line1.weight',\n",
       "              tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
       "                      [ 0.0139, -0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.0172],\n",
       "                      [-0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
       "                      ...,\n",
       "                      [ 0.0000, -0.0000, -0.0000,  ...,  0.0000,  0.0000, -0.0134],\n",
       "                      [-0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
       "                      [-0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000, -0.0000]],\n",
       "                     device='cuda:0')),\n",
       "             ('line1.bias',\n",
       "              tensor([ 4.2544e-02, -8.2663e-02, -8.3965e-03, -8.2125e-03, -1.0862e-02,\n",
       "                      -5.3105e-03, -1.8748e-02,  2.5894e-02, -1.3999e-02, -6.5175e-02,\n",
       "                      -2.3621e-02,  7.4452e-04, -1.9188e-02, -5.9922e-03, -1.1580e-01,\n",
       "                      -1.6055e-02, -1.6036e-02, -1.2057e-02, -4.6454e-03, -7.1031e-02,\n",
       "                       7.8805e-02,  1.2805e-03, -4.6194e-02, -3.5384e-02,  1.2786e-01,\n",
       "                      -2.2391e-02, -7.0065e-03,  1.9571e-01, -2.1801e-03,  5.4153e-02,\n",
       "                      -7.2329e-02, -9.3706e-02, -2.0608e-02,  2.7007e-02, -1.4204e-02,\n",
       "                      -3.1534e-02, -4.2868e-02,  8.3943e-02,  6.0647e-02, -1.9720e-03,\n",
       "                      -2.3308e-02, -1.6501e-02,  1.4916e-01, -1.2766e-01, -5.1229e-03,\n",
       "                       1.9891e-04, -1.4610e-02, -1.7541e-02, -5.8982e-03, -2.1333e-03,\n",
       "                      -3.3318e-02,  2.4968e-02, -1.0011e-02, -1.0138e-01, -2.8295e-02,\n",
       "                       9.2293e-03, -4.6388e-02, -8.8003e-03,  4.0450e-02, -2.0018e-01,\n",
       "                      -2.5321e-03, -6.5099e-02, -3.8091e-02,  4.0309e-02, -7.0978e-02,\n",
       "                      -9.7924e-03, -2.2415e-02,  2.8224e-02, -5.3327e-02, -1.8920e-02,\n",
       "                      -1.9435e-02,  1.6200e-02,  6.2336e-03, -3.1431e-02, -1.4936e-02,\n",
       "                      -1.2873e-02, -7.8307e-03, -2.1957e-02, -2.6738e-03, -5.6871e-03,\n",
       "                      -9.7909e-03,  1.0844e-03, -1.2544e-03, -5.3915e-03, -5.2858e-02,\n",
       "                      -7.5878e-03, -5.7674e-02,  1.2231e-01, -1.6399e-02,  2.9840e-04,\n",
       "                       2.4554e-03,  8.7234e-03, -2.2251e-03, -1.6858e-02, -8.8196e-02,\n",
       "                      -9.9271e-02, -6.7056e-02,  1.8530e-02, -1.5218e-01, -3.7328e-02,\n",
       "                      -3.4049e-03, -4.4889e-03,  4.3603e-03, -1.1762e-02, -5.8835e-02,\n",
       "                      -2.2177e-02,  2.1483e-01,  2.3752e-02, -1.5518e-01, -8.1920e-04,\n",
       "                      -7.4222e-02, -3.9668e-02, -5.0994e-03,  1.0571e-01, -4.9843e-02,\n",
       "                      -1.2972e-01, -4.7570e-02,  9.0486e-03,  8.4970e-03, -7.2409e-02,\n",
       "                       2.7652e-02, -1.5778e-02, -2.0258e-03,  9.5508e-02, -5.7777e-03,\n",
       "                      -1.5517e-02,  1.0541e-01, -1.0198e-02, -1.1759e-02, -3.3164e-03,\n",
       "                      -6.9117e-03,  3.4159e-02, -2.7890e-02, -1.9699e-02, -1.4143e-01,\n",
       "                       1.3184e-01, -1.3025e-02,  5.7010e-02, -3.6344e-02, -6.2006e-02,\n",
       "                      -1.0370e-01, -1.1986e-01, -1.1354e-02, -1.0966e-02, -1.2134e-01,\n",
       "                      -1.5777e-01, -5.6231e-03, -1.1637e-02, -2.9556e-04, -4.4300e-03,\n",
       "                       4.7979e-03,  1.3513e-01, -1.1169e-02, -5.5894e-03,  2.1829e-02,\n",
       "                      -1.0161e-02, -5.5050e-03, -1.4777e-02,  9.1040e-03, -8.0253e-03,\n",
       "                      -8.1866e-03, -6.5218e-02, -5.7889e-03,  3.5093e-02, -6.1628e-02,\n",
       "                       2.1963e-01,  4.8203e-02, -7.7834e-02, -5.2451e-02,  1.6585e-02,\n",
       "                      -2.5495e-02, -4.8534e-03, -1.6821e-02, -8.4287e-02, -6.2035e-02,\n",
       "                       1.0101e-02, -1.4062e-03, -2.2771e-02,  6.0797e-02, -2.1239e-02,\n",
       "                      -5.4236e-03, -9.0578e-03, -7.2049e-03, -6.7335e-02, -7.8702e-03,\n",
       "                       8.6906e-02, -1.0037e-02, -1.1809e-02, -1.9676e-02, -6.5099e-03,\n",
       "                      -1.0045e-02, -2.0291e-02, -9.5647e-02, -1.0104e-02, -1.9084e-02,\n",
       "                      -1.5054e-02, -4.6703e-03, -3.6107e-02, -2.0255e-02, -1.3262e-02,\n",
       "                      -4.7753e-02, -1.2251e-01, -1.5738e-02, -5.1205e-02, -2.9380e-03,\n",
       "                      -2.7531e-04, -1.2365e-02,  1.5422e-01, -9.2605e-02, -8.4211e-03,\n",
       "                       3.2710e-02, -2.1860e-03,  2.6760e-01, -1.5462e-01, -6.8985e-03,\n",
       "                      -8.8271e-03, -1.1538e-01, -8.8404e-02, -4.0605e-03, -1.3920e-01,\n",
       "                      -7.3393e-03, -3.4874e-02, -4.4157e-03,  6.3696e-03, -5.0535e-04,\n",
       "                      -8.3458e-03, -2.8859e-02, -1.3783e-01,  8.6528e-02,  1.8653e-02,\n",
       "                      -4.7154e-02, -1.9681e-02, -4.2285e-03,  1.2923e-05,  2.3662e-01,\n",
       "                      -1.0999e-02, -7.3250e-03, -2.5962e-02, -5.9289e-02, -3.9424e-02,\n",
       "                       1.3426e-01, -1.1096e-02,  2.2870e-02, -8.7251e-02, -1.4048e-02,\n",
       "                      -1.2984e-02,  2.4225e-03, -8.0685e-03,  2.2383e-01,  5.8851e-03,\n",
       "                       6.3025e-03,  1.1510e-03, -9.2901e-02,  1.5965e-01,  2.9932e-02,\n",
       "                      -9.1998e-03, -1.0359e-02, -5.4527e-03, -4.6049e-03, -2.3550e-02,\n",
       "                      -1.2166e-02, -5.6277e-02,  1.2670e-01,  2.2315e-01,  2.6687e-02,\n",
       "                      -3.8395e-02, -6.1921e-04, -7.5149e-02, -1.1896e-01, -2.0323e-02,\n",
       "                      -1.2604e-02,  2.3199e-02,  8.1942e-02, -1.6108e-02, -7.9639e-02,\n",
       "                      -1.5560e-02, -2.0141e-02, -5.5615e-03, -1.3794e-02, -3.9522e-02,\n",
       "                      -4.3462e-02, -1.7244e-02, -2.1105e-02,  8.7854e-02,  2.6244e-01,\n",
       "                       1.2957e-01,  1.1045e-01, -7.5018e-03,  2.7618e-02, -1.0103e-01,\n",
       "                      -6.9533e-02,  1.0962e-01,  1.4049e-02,  1.6286e-02, -5.3556e-03,\n",
       "                       1.8085e-03, -1.2216e-02,  2.9491e-02,  1.0227e-02, -1.0651e-01,\n",
       "                      -4.1424e-02, -2.3622e-02, -6.6580e-02, -2.6405e-02, -3.1076e-02,\n",
       "                       4.6704e-02, -3.7987e-02, -8.3337e-03, -6.1293e-02, -2.6655e-02,\n",
       "                      -9.2158e-02, -4.1025e-02, -7.3666e-02,  3.6232e-02, -5.9223e-02,\n",
       "                       3.5979e-03, -3.4513e-02, -3.2992e-02, -5.4844e-03, -8.4823e-03,\n",
       "                       1.2463e-01, -2.1033e-02,  2.3405e-01, -6.8432e-02, -2.7042e-03,\n",
       "                      -2.5261e-02, -4.6475e-03, -7.9387e-03, -2.0844e-02, -5.3899e-03,\n",
       "                      -6.2231e-02, -1.4370e-02,  6.7009e-02,  1.1468e-01,  6.6835e-02,\n",
       "                      -3.6420e-02,  4.8531e-03,  9.2878e-02, -2.1194e-02, -2.1405e-02,\n",
       "                      -4.8870e-02, -8.7278e-03, -2.5957e-02, -1.1127e-02, -1.4461e-02,\n",
       "                      -3.1161e-02, -8.5909e-02, -9.2012e-04, -1.1199e-02, -1.2818e-01,\n",
       "                       9.4840e-03, -2.0858e-02,  4.0576e-03,  5.1054e-03, -1.0401e-01,\n",
       "                      -1.0780e-01, -2.0829e-03, -1.7282e-03, -4.4023e-03, -2.0874e-03,\n",
       "                      -1.0613e-02, -1.3173e-02,  5.0985e-04,  3.1996e-03, -1.1648e-01,\n",
       "                      -6.6085e-02, -2.8614e-02, -9.9301e-03, -1.0305e-02, -3.9238e-03,\n",
       "                       1.2410e-02,  1.2930e-02,  3.0178e-03,  5.0485e-03, -9.0044e-03,\n",
       "                      -1.1714e-02, -2.3250e-02,  9.3166e-02,  5.2826e-03, -3.0758e-02,\n",
       "                      -3.6351e-02, -2.5778e-02, -1.5642e-01,  3.8165e-02, -2.5636e-02,\n",
       "                      -6.1370e-03,  8.6716e-02, -3.8207e-03,  2.9803e-03, -1.0284e-02,\n",
       "                       4.1471e-02,  4.2682e-02, -8.5646e-03, -2.1886e-02, -2.5505e-01,\n",
       "                      -1.7248e-02, -1.4479e-02,  7.1206e-02, -1.6973e-01,  3.0352e-02,\n",
       "                      -7.8172e-03,  2.7591e-02, -4.8536e-03,  1.9314e-01, -3.8092e-03,\n",
       "                       1.4304e-01,  1.8521e-02, -1.7676e-02, -6.0480e-03, -9.1669e-03,\n",
       "                       2.5543e-03,  1.3268e-01,  1.1783e-03, -1.1106e-02, -1.3580e-02,\n",
       "                      -1.2675e-03, -4.3186e-02, -1.7685e-02, -6.3510e-02, -2.7291e-02,\n",
       "                      -3.4894e-03, -6.2923e-02, -5.4264e-02,  3.6968e-03, -6.4416e-03,\n",
       "                      -4.0502e-02, -9.1603e-02,  3.5278e-03, -1.5527e-01, -8.8990e-03,\n",
       "                       3.7580e-02, -8.8848e-03,  9.5168e-02,  1.6209e-01,  1.1666e-02,\n",
       "                      -1.2881e-02,  1.1120e-04,  9.7696e-05, -7.9566e-02, -8.6403e-03,\n",
       "                      -2.8385e-02,  1.1253e-01, -1.0852e-02, -5.4032e-02, -1.4906e-02,\n",
       "                      -2.8813e-02,  8.6090e-02, -1.1933e-01, -1.8083e-02, -5.7528e-02,\n",
       "                      -3.2048e-02, -1.9805e-03, -9.8768e-02,  1.2977e-02, -1.8378e-02,\n",
       "                       1.0496e-01, -1.0192e-01, -5.3143e-02, -1.7580e-03, -6.2542e-02,\n",
       "                       8.4470e-02,  1.0059e-01,  7.7997e-03, -1.4157e-02, -5.1046e-02,\n",
       "                      -4.0866e-03,  1.0434e-01, -1.2788e-01, -1.4376e-01, -9.3540e-03,\n",
       "                      -5.7073e-02, -7.5190e-03, -4.4399e-03, -1.3537e-01, -2.2540e-02,\n",
       "                       2.3875e-03, -6.0200e-02, -6.4005e-02,  1.4896e-01, -7.8115e-03,\n",
       "                       1.7327e-03,  7.6205e-02,  5.4399e-02, -3.4544e-02, -2.0392e-02,\n",
       "                      -5.2001e-02,  1.6499e-02,  7.2301e-02, -2.5463e-02, -1.0685e-01,\n",
       "                      -6.3544e-03, -6.5905e-03,  5.9967e-03,  1.4722e-02, -7.4968e-03,\n",
       "                       1.7996e-02,  2.9528e-02,  8.4365e-02,  9.2466e-02, -1.4955e-02,\n",
       "                      -8.6616e-03, -1.2946e-02, -1.6043e-02, -7.3474e-03, -4.1902e-03,\n",
       "                       8.3894e-02, -1.3794e-02, -1.9572e-02,  1.0810e-01,  9.9450e-04,\n",
       "                      -2.3048e-03,  6.3151e-03], device='cuda:0')),\n",
       "             ('line2.weight',\n",
       "              tensor([[ 0.0000, -0.0515, -0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
       "                      [ 0.0000, -0.1449, -0.0000,  ...,  0.0000,  0.0495, -0.0000],\n",
       "                      [-0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
       "                      ...,\n",
       "                      [ 0.0000, -0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0615],\n",
       "                      [-0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0544,  0.0475],\n",
       "                      [ 0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000,  0.0000]],\n",
       "                     device='cuda:0')),\n",
       "             ('line2.bias',\n",
       "              tensor([-3.2449e-02,  2.7594e-01,  1.1460e-01,  3.7026e-01,  1.2091e-01,\n",
       "                      -2.2769e-02,  1.6978e-01,  2.6811e-01,  2.1491e-01,  4.0413e-02,\n",
       "                      -1.3919e-02,  4.9829e-02,  2.2171e-01, -1.6731e-02,  1.0874e-01,\n",
       "                       5.1741e-02,  1.1128e-01,  4.2729e-02,  2.5578e-01, -7.2732e-05,\n",
       "                       1.5214e-01,  2.8929e-01, -4.9892e-02, -3.0486e-02,  1.1104e-01,\n",
       "                       1.3143e-01,  2.6279e-02, -2.6098e-02,  9.8452e-02,  5.6098e-02,\n",
       "                       9.4101e-02,  2.0923e-01,  3.5397e-01,  7.6082e-02, -9.7388e-02,\n",
       "                      -2.2522e-03,  3.6921e-01,  2.8054e-01, -5.6760e-02,  1.2361e-01,\n",
       "                       8.8539e-02,  1.8460e-02, -1.9454e-02,  1.6255e-01,  9.2635e-02,\n",
       "                       3.0087e-01,  2.6235e-01,  1.9502e-01,  1.3188e-01,  1.1627e-01,\n",
       "                       5.0030e-02, -6.3513e-02,  1.0844e-01,  3.2403e-01,  3.7714e-02,\n",
       "                       4.0208e-02,  1.3334e-01, -4.5786e-02,  1.0830e-01,  7.2212e-02,\n",
       "                       8.2615e-02,  7.9511e-02,  3.9841e-02,  1.0573e-01,  9.3377e-02,\n",
       "                       9.8933e-02, -1.7593e-02,  2.1919e-02, -2.7934e-02, -1.2685e-02,\n",
       "                       1.0037e-01,  1.1584e-01,  4.0092e-01,  1.4848e-01,  9.9541e-02,\n",
       "                       6.4211e-03,  1.1375e-01, -4.1394e-02, -4.6169e-03,  2.8953e-01,\n",
       "                       2.2137e-01,  4.7434e-02, -2.1960e-02,  1.0260e-01,  8.5608e-02,\n",
       "                       3.7100e-01,  1.3795e-02, -2.0252e-02,  3.1906e-02,  2.4055e-01,\n",
       "                      -7.3525e-02,  4.9752e-02,  7.0206e-02,  1.0255e-01, -6.6271e-02,\n",
       "                       7.4885e-02,  1.5121e-01,  1.2830e-01,  1.2496e-01, -6.0447e-02,\n",
       "                       6.9717e-02,  3.0031e-01,  6.7806e-02,  1.9376e-01, -2.3857e-02,\n",
       "                       1.5008e-01,  3.4379e-01,  3.6509e-01,  6.3632e-02,  4.2746e-02,\n",
       "                      -8.4116e-02,  7.1845e-02, -6.0941e-02,  3.2564e-02,  2.9002e-01,\n",
       "                       4.2807e-01,  1.5699e-01, -1.8130e-02, -3.7423e-02, -3.5150e-03,\n",
       "                       4.9713e-02,  4.1171e-02,  2.2034e-01,  2.4349e-01,  3.7633e-03,\n",
       "                       1.8483e-02,  1.9965e-01,  6.1888e-02], device='cuda:0')),\n",
       "             ('line3.weight',\n",
       "              tensor([[-0.0000,  0.1782, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000,\n",
       "                        0.0000, -0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.1238,\n",
       "                       -0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "                       -0.1828, -0.0000,  0.0000,  0.0000, -0.1475, -0.0000, -0.0000,  0.1324,\n",
       "                        0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.1354,  0.0000, -0.1275,\n",
       "                        0.1769,  0.0000,  0.0000, -0.0000,  0.1471, -0.0000, -0.0000,  0.0000,\n",
       "                        0.0000, -0.1322,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "                       -0.0000, -0.0000, -0.1181, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "                       -0.1453, -0.0000,  0.0000, -0.0000, -0.0000, -0.1188, -0.0000, -0.0000,\n",
       "                        0.0000,  0.1220, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000,\n",
       "                        0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.1211, -0.0000, -0.0000,\n",
       "                       -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.1556, -0.0000,  0.0000,\n",
       "                        0.0000, -0.1472, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.1176,\n",
       "                        0.0000,  0.0000,  0.1339,  0.0000, -0.1293,  0.0000,  0.0000, -0.1453,\n",
       "                        0.0000,  0.0000,  0.0000,  0.1524,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "                       -0.0000, -0.0000,  0.1176,  0.0000, -0.0000,  0.0000, -0.1281, -0.0000],\n",
       "                      [ 0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.1660,\n",
       "                        0.0000,  0.0000,  0.0000,  0.0000, -0.1254, -0.0000,  0.1212,  0.1212,\n",
       "                        0.1356,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000,\n",
       "                        0.0000,  0.1510, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000,\n",
       "                       -0.0000, -0.0000, -0.0000,  0.1376, -0.0000, -0.2217,  0.0000,  0.0000,\n",
       "                       -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.1588,\n",
       "                       -0.0000,  0.0000,  0.0000, -0.0000,  0.1254, -0.1629,  0.0000,  0.0000,\n",
       "                        0.0000, -0.0000,  0.0000, -0.0000,  0.1447, -0.0000,  0.0000,  0.0000,\n",
       "                        0.0000, -0.0000,  0.0000,  0.1552, -0.0000, -0.0000,  0.0000,  0.1208,\n",
       "                       -0.0000, -0.1206,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.1332,\n",
       "                       -0.0000, -0.0000,  0.0000,  0.0000,  0.1329, -0.0000,  0.0000,  0.0000,\n",
       "                        0.0000, -0.1383, -0.0000, -0.0000,  0.1252,  0.0000,  0.0000,  0.0000,\n",
       "                       -0.0000,  0.0000,  0.1304,  0.0000, -0.0000, -0.1855, -0.0000, -0.1621,\n",
       "                       -0.0000, -0.0000, -0.0000, -0.1439,  0.0000,  0.1249,  0.0000,  0.0000,\n",
       "                       -0.0000, -0.1336, -0.1252, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "                        0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,  0.1270,  0.0000]],\n",
       "                     device='cuda:0')),\n",
       "             ('line3.bias', tensor([0.0151, 0.0179], device='cuda:0'))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pruned_model.state_dict(), 'pruned_model1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pruned_model1.pth文件大小:\n",
      "\t38241888字节\n",
      "\t36.47M\n"
     ]
    }
   ],
   "source": [
    "file_size = os.path.getsize('pruned_model1.pth')\n",
    "print('{}文件大小:\\n\\t{}字节\\n\\t{}M'.format('pruned_model1.pth', file_size, round(file_size/1024**2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: average loss: 0.5400, accuracy: 1854/2500 (74%)\n",
      "Cost: 6.404947519302368\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "test(pruned_model, 'cuda', test_loader)\n",
    "end = time.time()\n",
    "print('Cost:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color='red'>可见这样处理后，模型无论在大小上还是在推理速度上均无明显提升，原始是因为经过剪枝操作后虽然将大部分的权重都变为0了，但是计算机在存储的时候还是使用的相同大小的空间存储0。要想真正压缩模型还需要进一步处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mask)):\n",
    "    # 将mask值由float转化为bool\n",
    "    mask[i] = mask[i] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mask, 'mask.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask.pth文件大小:\n",
      "\t9560134字节\n",
      "\t9.12M\n"
     ]
    }
   ],
   "source": [
    "file_size = os.path.getsize('mask.pth')\n",
    "print('{}文件大小:\\n\\t{}字节\\n\\t{}M'.format('mask.pth', file_size, round(file_size/1024**2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 小例子（稀疏编码）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.tensor([[False, True, False], [True, True, False], [True, False, True]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 4, 5, 7, 9])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_a = torch.masked_select(a, mask)\n",
    "save_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [2, 0],\n",
       "        [2, 2]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = mask.nonzero()\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7b7784f71433>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  parms = torch.tensor(mask, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "parms = torch.tensor(mask, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(index)):\n",
    "    r, c = index[i]\n",
    "    parms[r, c] *= save_a[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 2., 0.],\n",
       "        [4., 5., 0.],\n",
       "        [7., 0., 9.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对剪枝后的模型采用稀疏编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.load('mask.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "parms = torch.load('pruned_model1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_layer_name = [i for i in list(parms.keys()) if 'weight' in i]\n",
    "for i in range(len(weight_layer_name)):\n",
    "    parms[weight_layer_name[i]] = torch.masked_select(parms[weight_layer_name[i]], mask[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(parms, 'new_parms.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask.pth文件大小:\n",
      "\t9560134字节\n",
      "\t9.12M\n",
      "new_parms.pth文件大小:\n",
      "\t7652338字节\n",
      "\t7.3M\n",
      "一共16.42M\n"
     ]
    }
   ],
   "source": [
    "file_size1 = os.path.getsize('mask.pth')\n",
    "print('{}文件大小:\\n\\t{}字节\\n\\t{}M'.format('mask.pth', file_size1, round(file_size1/1024**2, 2)))\n",
    "file_size2 = os.path.getsize('new_parms.pth')\n",
    "print('{}文件大小:\\n\\t{}字节\\n\\t{}M'.format('new_parms.pth', file_size2, round(file_size2/1024**2, 2)))\n",
    "print('一共{}M'.format(round((file_size1+file_size2)/1024**2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color='red'>经过稀疏编码后，模型参数下降到了16.42M，相比原始的36.47M缩减了一半多"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 稀疏编码还原"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.load('mask.pth')  \n",
    "parms = torch.load('new_parms.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv1.weight',\n",
       " 'conv2.weight',\n",
       " 'conv3.weight',\n",
       " 'line1.weight',\n",
       " 'line2.weight',\n",
       " 'line3.weight']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_layer_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_layer_name = [i for i in list(parms.keys()) if 'weight' in i]\n",
    "new_parms = deepcopy(parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1782, -0.1238, -0.1828, -0.1475,  0.1324,  0.1354, -0.1275,  0.1769,\n",
       "         0.1471, -0.1322, -0.1181, -0.1453, -0.1188,  0.1220,  0.1211, -0.1556,\n",
       "        -0.1472,  0.1176,  0.1339, -0.1293, -0.1453,  0.1524,  0.1176, -0.1281,\n",
       "        -0.1660, -0.1254,  0.1212,  0.1212,  0.1356,  0.1510,  0.1376, -0.2217,\n",
       "        -0.1588,  0.1254, -0.1629,  0.1447,  0.1552,  0.1208, -0.1206, -0.1332,\n",
       "         0.1329, -0.1383,  0.1252,  0.1304, -0.1855, -0.1621, -0.1439,  0.1249,\n",
       "        -0.1336, -0.1252,  0.1270], device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parms[weight_layer_name[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-a6e82f802d5c>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  new_parms[weight_layer_name[i]] = torch.tensor(mask[i], dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "new_parms[weight_layer_name[i]] = torch.tensor(mask[i], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-40-b7e66ad30bfe>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  new_parms[weight_layer_name[i]] = torch.tensor(mask[i], dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(weight_layer_name)):\n",
    "    new_parms[weight_layer_name[i]] = torch.tensor(mask[i], dtype=torch.float32)\n",
    "    for j in range(len(index)):\n",
    "        new_parms[weight_layer_name[i]][new_parms[weight_layer_name[i]] != 0] = parms[weight_layer_name[i]].to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用还原的权重进行模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_model.load_state_dict(new_parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 148, 148]             448\n",
      "         MaxPool2d-2           [-1, 16, 74, 74]               0\n",
      "              ReLU-3           [-1, 16, 74, 74]               0\n",
      "            Conv2d-4           [-1, 32, 72, 72]           4,640\n",
      "         MaxPool2d-5           [-1, 32, 36, 36]               0\n",
      "              ReLU-6           [-1, 32, 36, 36]               0\n",
      "            Conv2d-7           [-1, 64, 34, 34]          18,496\n",
      "         MaxPool2d-8           [-1, 64, 17, 17]               0\n",
      "              ReLU-9           [-1, 64, 17, 17]               0\n",
      "          Flatten-10                [-1, 18496]               0\n",
      "           Linear-11                  [-1, 512]       9,470,464\n",
      "             ReLU-12                  [-1, 512]               0\n",
      "          Dropout-13                  [-1, 512]               0\n",
      "           Linear-14                  [-1, 128]          65,664\n",
      "             ReLU-15                  [-1, 128]               0\n",
      "          Dropout-16                  [-1, 128]               0\n",
      "           Linear-17                    [-1, 2]             258\n",
      "================================================================\n",
      "Total params: 9,559,970\n",
      "Trainable params: 9,559,970\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.26\n",
      "Forward/backward pass size (MB): 6.91\n",
      "Params size (MB): 36.47\n",
      "Estimated Total Size (MB): 43.64\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(pruned_model, (3, 150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: average loss: 0.5400, accuracy: 1854/2500 (74%)\n",
      "Cost: 5.528990983963013\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "test(pruned_model, 'cuda', test_loader)\n",
    "end = time.time()\n",
    "print('Cost:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通道剪枝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color='red'>将不重要的卷积核得到的特征图去掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型量化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color='red'>将模型参数的精度类型减小（float32 -> int8）\n",
    "<br>狭义上的量化：连续 -> 离散\n",
    "<br>神经网络的量化：float32 -> int8, int4, int2等，缩小可表示的空间大小 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 知识蒸馏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color='red'>老师教学生<br>知识蒸馏通常用于模型压缩，用一个已经训练好的模型A去“教”另外一个模型B。这两个模型称为老师-学生模型。<br>通常模型A比模型B更强。在模型A的帮助下，模型B可以突破自我，学得更好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "611.333px",
    "left": "94px",
    "top": "110px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
